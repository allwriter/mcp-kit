# mcp-kit
  
### ❓MCP 서버가 뭐야?
- 정의: LLM(예: ChatGPT) 같은 AI 모델이 외부 기능이나 데이터를 활용할 수 있게 해주는 중간 서버입니다.
- 역할: 챗봇이 “바로 실행할 수 없는 기능”을 대신 처리해 주는 플러그인 서버라고 보면 됩니다.
- 즉, MCP 서버 = LLM을 위한 확장 기능 서버
</br>

### ❓LLM은 어떻게 MCP 함수를 알고, 그 규격대로 호출해?
- MCP 서버는 자신이 제공하는 기능을 “스펙(spec)” 형태로 LLM에게 알려줍니다.
- MCP 서버는 “내가 지원하는 함수(action)와 파라미터, 반환 형식”을 LLM이 이해할 수 있게 Capability 등록을 합니다.
```
{
  "capabilities": [
    {
      "name": "get_user",
      "description": "사용자 정보를 조회합니다.",
      "parameters": {
        "id": "integer"
      }
    },
    {
      "name": "ping",
      "description": "서버 응답 확인",
      "parameters": {}
    }
  ]
}
```
</br>

### ❓아 그럼 LLM은 Description을 직접 해석해서 사용하는거야?
- 네, 맞아요 LLM은 description을 직접 해석해서, 사용자의 질문과 MCP 기능을 연결합니다.
- description이 부실하면 LLM이 오해해서 틀린 함수 호출을 할 수 있어요.
- 그래서 좋은 MCP 서버 = “잘 짜여진 API” + “LLM 친화적인 설명” 두 가지가 동시에 필요합니다. 
</br>

### ❓ChatGPT한테 내가 개발한 MCP를 붙여서 사용할 수 있나?
- 현재 제 환경(여기서 실행되는 ChatGPT)은 외부 네트워크에 임의로 접속하거나, 임의 서버와 소켓 연결을 맺을 권한이 없어요.
- 따라서 제가 만든 요청을 직접 당신의 MCP 서버에 보내는 방식(테스트 클라이언트처럼)은 불가능합니다.
      
✅ 하지만 가능한 방법
- 당신이 MCP 서버를 로컬이나 클라우드에 띄움
- MCP 클라이언트/프록시를 ChatGPT 같은 LLM 앱에 붙임
- 현재 OpenAI의 ChatGPT에서도 MCP 지원이 점차 열리고 있어요.
- 예를 들어 VS Code 확장, LangChain, LlamaIndex 같은 프레임워크에서 MCP 서버를 붙일 수 있습니다.
</br>

### ❓그럼 내가 테스트 할 챗봇은 직접 만들어야해?
- 당신이 만든 MCP 서버를 테스트하려면 "챗봇 클라이언트"가 필요합니다.
  
✅ MCP 서버 테스트 방법  
1) 직접 호출 → 빠르고 쉽지만 “LLM이 description을 읽고 판단”하는 부분은 테스트가 안 됨  
2) LLM 클라이언트 직접 구현하여 테스트
3) 이미 있는 프레임워크 활용 → LangChain, VS Code MCP 클라이언트(OpenAI가 공식 지원 중)
</br>

### ❓챗봇 만들어 이용하는 것과 VS Code 클라이언트 이용하는 것에 어떤 차이가 있나?
- 최소 기능 챗봇 클라이언트
장점: 테스트 환경을 완전히 커스터마이징 가능  
단점: 직접 구축·운영 부담 있음  
  
- VS Code MCP 클라이언트
장점: 세팅만 하면 바로 사용 가능, UI 완비  
단점: 자유도는 상대적으로 제한적 (VS Code 환경에 종속)
</br>

### ❓그럼 내가 MCP서버만 빠르게 개발/테스트해야 하는 입장이라면 직접 챗봇을 만들거나 LangChain 같은 프레임워크를 사용하는 것보다 VS Code 클라이언트를 사용하는 것이 효율적이겠네?
- MCP 서버 동작 확인이 목적이라면 VS Code MCP 클라이언트가 제일 효율적이고,
- MCP를 실제 서비스에 녹이기가 목적이라면 직접 챗봇이나 LangChain 같은 프레임워크가 맞습니다.  
👌
</br>
 
### ❓LLM이 capability 참조한다고 했잖아 그건 어디 세팅해?
제가 앞에서 “LLM은 description과 capability를 참조해서 함수를 호출한다”고 말씀드렸는데,
그걸 어디서 따로 세팅하는 게 아니라, fastmcp가 자동으로 만들어주는 겁니다.
  
**1. @app.function() 데코레이터**
- fastmcp는 이 데코레이터를 만나면 함수 메타데이터를 자동으로 수집합니다.
- 수집되는 정보:
  - 함수 이름
  - 파라미터 이름 & 타입 힌트
  - docstring (함수 설명)
</br>

**2. MCP 프로토콜 초기화 과정**
- LLM 클라이언트(Copilot, Cursor, Claude 등)가 MCP 서버에 처음 붙으면:
  1. initialize 요청을 보냄
  2. MCP 서버(fastmcp)가 **capabilities 목록(JSON)**을 응답
  3. 이 목록에 포함된 함수들의 name/description/parameters가 그대로 전달됨
- LLM은 이걸 “메뉴판”처럼 보고, 어떤 함수가 있는지 학습 없이도 알 수 있음
</br>
 
**3. 내가 따로 세팅할 곳은?**
- 따로 JSON을 만들거나 설정할 필요 ❌
- 오직 Python 함수에 타입힌트 + docstring 잘 써주는 게 전부
- (예: docstring이 비어 있으면 LLM이 헷갈림 → 자연어 설명을 꼭 넣어주는 게 중요)
</br>
 
### 구조는 대충 알았어 이제 내가 요구사항을 줄게 FastMCP, postgresql, openai 5.0 연동 사용해서 코드를 짜줘
</br>
 
# 📌 요구사항 정리: 개발자 업무 분배 MCP 도구 (feat.ChatGPT)
## 1. 사용자 역할
- 관리자
  - 개발자 정보 입력 가능
    - 프로젝트명
    - 이름
    - 경력(년)
    - 보유 기술 목록
    - 업무 경험(자유 텍스트)
    - 현재 업무량(workload)
  - 태스크(TASK) 등록 가능
    - 담당 개발자 (자동 배정)
    - 요구사항 설명
    - 필요 기술 목록
- 개발자
  - 본인에게 배정된 태스크를 조회 가능
  - 태스크 완료 시 상태 변경 + 처리 상세 기록 입력
    - 처리 내용
    - 처리 방법
    - 관련 DB
  
## 2. 태스크 자동 분배 규칙
- 관리자가 새로운 태스크를 등록하면 MCP 서버가 개발자에게 자동 할당
- 우선순위:
  1) 과거 유사한 태스크 경험 여부 (최우선)
  2) 업무량이 적은 개발자 (단, 업무량 차이가 지나치게 크면 무조건 적은 사람에게 배정)
  3) 요구 기술과 보유 기술 매칭 정도
  
- (선택) LLM 활용
  - 단순 규칙 기반이 아니라, LLM이 적합도를 판단해서 가장 적절한 개발자를 추천할 수 있음
  - 즉, 규칙 + LLM 보정 조합 가능
  
## 3. 개발자 업무 조회
- 개발자는 MCP를 통해 배정된 태스크 목록을 확인
- 각 태스크에 대해 연관 과거 태스크 목록을 함께 제공
  - 비슷한 업무 처리 방식, 해결 방법 등을 참고 가능
  - 지식 재사용을 촉진
  
## 4. 태스크 완료 처리
- 개발자가 태스크를 완료할 때 입력:
  - 처리 내용
  - 처리 방법
  - 관련 DB
- 이 정보는 태스크 테이블에 저장
- 추후 새로운 태스크 분배 시 유사 태스크 참고 자료로 제공
  
## 5. DocString 작성 방식
- 각 MCP 함수에 시나리오 기반 자연어 설명을 DocString으로 포함
- 예:
```python
@app.function()
def admin_add_task(...):
    """
    [관리자] 태스크를 등록합니다.
    시나리오:
      관리자가 새 업무를 시스템에 등록하면,
      MCP 서버는 과거 유사도 / 업무량 / 기술 매칭 / (선택) LLM 보정 을 종합해
      자동으로 적절한 개발자를 선택합니다.
      개발자는 이후 배정된 업무와 함께 과거 유사 업무를 참고할 수 있습니다.
    """
```
  
## 6. 테스트 데이터 (Demo 시드)
- 관리자용 함수 제공: seed_demo_data()
- 실행 시:
 - 예시 개발자 3~4명 등록
 - 예시 완료된 태스크 3~4개 삽입
- 이후:
  - 새 태스크를 등록하면 자동 분배 로직이 정상 작동하는지 바로 확인 가능
  
## 7. 구현 방식
- 기본: FastMCP + PostgreSQL 기반 규칙 엔진
- 확장: OpenAI GPT-5 (선택)
  - 태스크 요구사항 + 개발자 프로필을 입력
  - “가장 적합한 개발자”를 JSON 형식으로 출력받아 배정
  - 규칙 기반 점수와 LLM 점수를 혼합해 최종 선정
  
✅ 요약:
- 관리자: 개발자/태스크 등록 → 자동 분배
- 개발자: 내 업무 확인 + 완료 처리 기록
- 분배 규칙: 유사 경험 → 업무량 → 기술 매칭 (+LLM)
- 완료 시 기록을 남겨 “유사 태스크 추천”에 활용
- DocString은 시나리오 기반 자연어로 작성
- 테스트 데이터 생성 함수 포함
